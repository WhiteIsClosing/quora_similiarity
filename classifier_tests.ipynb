{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Load Required Python Libraries\n",
    "##########################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pickle\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Loads in Quora Dataset\n",
    "##########################################\n",
    "#Training Dataset\n",
    "data = pd.read_csv('train.csv')\n",
    "data['question1'] = data['question1'].astype(str)\n",
    "data['question2'] = data['question2'].astype(str)\n",
    "\n",
    "test_data = pd.read_csv('test.csv')\n",
    "test_data['question1'] = test_data['question1'].astype(str)\n",
    "test_data['question2'] = test_data['question2'].astype(str)\n",
    "\n",
    "#Drop irrelevant features\n",
    "data = data.drop(['id', 'qid1', 'qid2'], axis=1)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Create a the total word vocabulary, defined over all the test and training questions\n",
    "##########################################\n",
    "\n",
    "complete_vocab_list= []\n",
    "for df in [data]:\n",
    "    for i in range(1, 3):\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectorizer.fit_transform(df['question'+str(i)])\n",
    "        complete_vocab_list = list(set(complete_vocab_list + vectorizer.get_feature_names()))\n",
    "complete_vocab_list = list(set(complete_vocab_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Print out dictionary to be used in other classifier models\n",
    "word_dict = open('word_dictionary_training_set.txt', 'wb')\n",
    "complete_vocab_list = [x.encode('ascii', 'ignore') for x in complete_vocab_list]\n",
    "for item in complete_vocab_list:\n",
    "    word_dict.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_questions = data['question1'] + data['question2']\n",
    "total_questions = [x for x in total_questions if type(x) != float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Create a tfidf matrix using the complete vocab list and then classify according to the matrix\n",
    "##########################################\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english', vocabulary = complete_vocab_list)\n",
    "vectorizer.fit(total_questions)\n",
    "q1_idf = vectorizer.transform(data['question1'])\n",
    "q2_idf = vectorizer.transform(data['question2'])\n",
    "q3_idf = vectorizer.transform(test_data['question1'])\n",
    "q4_idf = vectorizer.transform(test_data['question2'])\n",
    "\n",
    "#Generate the features from the training data\n",
    "features_idf = q1_idf - q2_idf\n",
    "y = data.ix[:,'is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Create a Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(criterion='entropy', max_features = 300)\n",
    "#Create a cross_validation accuracy score\n",
    "scores = cross_val_score(rf_classifier, features_idf, y, cv=5)\n",
    "rf_accuracy = reduce(lambda x, y: x + y, scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.784454223877\n"
     ]
    }
   ],
   "source": [
    "#Look at the cross validated accuracy\n",
    "print rf_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features=300, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the random forest classifier to the training data\n",
    "rf_classifier.fit(features_idf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export tf-idf difference, entropy based Random Forest Classifier\n",
    "filename = 'tfidf_rf_entropy.sav'\n",
    "pickle.dump(rf_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predict using the test set and replace with cross validated average accuracy\n",
    "test_features_idf = q3_idf - q4_idf\n",
    "test_prediction = rf_classifier.predict(test_features_idf)\n",
    "test_prediction = list(test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "btest_prediction = [1 - rf_accuracy if x == 0 else rf_accuracy for x in test_prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Submit using the predicted probabilities from the RF, averaged over the cross-validated results\n",
    "test_results_df = pd.DataFrame({'test_id':test_data['test_id'], 'is_duplicate': btest_prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_results_df.to_csv('submission_tfidf_rf.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Create a linear SVM Classifier\n",
    "svm_classifier = svm.SVC(kernel = 'linear')\n",
    "#Create a cross_validation accuracy score\n",
    "scores = cross_val_score(svm_classifier, features_idf, y, cv=5)\n",
    "svm_accuracy = reduce(lambda x, y: x + y, scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export tf-idf difference, linear SVM model\n",
    "filename = 'tfidf_linear_svm.sav'\n",
    "pickle.dump(rf_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#For test questions with a null value, we know that if ! both null then P(duplicate) = 0\n",
    "confident_results = list(test_data[test_data['question1'] == 'nan']['test_id']) + list(test_data[test_data['question2'] == 'nan']['test_id'])\n",
    "for test_id in confident_results:\n",
    "    test_results_df.loc[test_id, 'is_duplicate'] = 0\n",
    "#Look at the result\n",
    "print test_results_df.loc[confident_results[0], 'is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
