{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Load Required Python Libraries\n",
    "##########################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Loads in Quora Dataset\n",
    "##########################################\n",
    "#Training Dataset\n",
    "data = pd.read_csv('/Users/Priscilla/Desktop/QuoraDataset/train.csv')\n",
    "\n",
    "#Drop irrelevant features\n",
    "data = data.drop(['id', 'qid1', 'qid2'], axis=1)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Feature Engineering Method 1: \n",
    "# Creating new input variables to improve ML algorithm performance\n",
    "##########################################\n",
    "#Feature: Length of Question\n",
    "#Apply length function to every data.question1 & data.question2 observation\n",
    "data['len_q1'] = data.question1.apply(lambda x: len(str(x)))\n",
    "data['len_q2'] = data.question2.apply(lambda x: len(str(x)))\n",
    "\n",
    "#Feature: Difference in length between the Questions\n",
    "#Substract len_q1 from len_q2\n",
    "data['len_diff'] = data.len_q1 - data.len_q2\n",
    "\n",
    "#Feature: Character count of Question\n",
    "#Strip whitespace in data.question1 & data.question2 and apply the length function\n",
    "data['len_char_q1'] = data.question1.apply(lambda x: len(str(x).replace(' ', '')))\n",
    "data['len_char_q2'] = data.question2.apply(lambda x: len(str(x).replace(' ', '')))\n",
    "\n",
    "#Feature: Word count of Question\n",
    "#Call split function on every data.question1 & data.question2 observation and apply the length function\n",
    "data['len_word_q1'] = data.question1.apply(lambda x: len(str(x).split()))\n",
    "data['len_word_q2'] = data.question2.apply(lambda x: len(str(x).split()))\n",
    "\n",
    "#Feature: Common words between the Questions\n",
    "#Intersection of data.question1 and data.question2\n",
    "#Set function is applied so repeated words in a question is omitted from the final common word count\n",
    "#Axis=1 to calculate the means column-wise (-->) rather than the default of Axis=0 to calculate the means row-wise(v)\n",
    "data['len_common_words'] = data.apply(lambda x: len(set(str(x['question1']).lower().split()).intersection(set(str(x['question2']).lower().split()))), axis=1)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Feature Engineering Method 2:\n",
    "# Create Bag Of Words Model with Tfidf Normalization\n",
    "##########################################\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Obtain the complete vocabulary for the entire dataset\n",
    "questions_combined = list(data.ix[:,'question1']) + list(data.ix[:,'question2'].values.astype(str))\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(questions_combined)\n",
    "\n",
    "#86153 unique vocabulary words question1 & question2 combined\n",
    "complete_vocab = vectorizer.get_feature_names()\n",
    "\n",
    "#Generate tfidf values for question1 and question2 based on the complete vocabulary of the dataset\n",
    "vectorizer_q1 = TfidfVectorizer(vocabulary = complete_vocab)\n",
    "vectorizer_q2 = TfidfVectorizer(vocabulary = complete_vocab)\n",
    "tfidf_question1 = vectorizer_q1.fit_transform(data.question1)\n",
    "tfidf_question2 = vectorizer_q2.fit_transform(data.question2.values.astype(str))\n",
    "\n",
    "#Substract the difference of the tfidf weight matricies for the two questions\n",
    "#Will be 0 if the words are weighted the same in both questions (similar significance contribution)\n",
    "diff_idf = tfidf_question1 - tfidf_question2\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Feature Engineering Method 3:\n",
    "# Doc2Vec Model\n",
    "##########################################\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Split the dataset into training and testing datasets\n",
    "##########################################\n",
    "#Loads the library required for splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Method 1 Features\n",
    "# features = data.ix[:,'len_q1':]\n",
    "\n",
    "#Method 2 Features\n",
    "features = diff_idf\n",
    "y = data.ix[:,'is_duplicate']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.2)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=2, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################\n",
    "# Random Forest Classifier\n",
    "##########################################\n",
    "#Loads required libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Create a Random Forest Classifer (clf by convention = 'classifier')\n",
    "clf = RandomForestClassifier(n_jobs=2) #n_jobs = # of jobs in run in parallel for fit and predict\n",
    "\n",
    "#Train the Random Forest Classifier\n",
    "clf.fit(X_train, y_train)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Apply Random Forest Classifer on the testing split of the dataset\n",
    "##########################################\n",
    "#Predicts the outcome variable of the testing split of the dataset\n",
    "test_prediction = clf.predict(X_test)\n",
    "\n",
    "#Prediction probability for the value of the outcome variable (0 or 1)\n",
    "test_prediction_proba = clf.predict_proba(X_test)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70306077046282545"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################\n",
    "# Apply Logloss function to Test Dataset Output\n",
    "##########################################\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "log_loss(np.array(y_test), test_prediction_proba)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preview newly added features to the dataset\n",
    "# pd.options.display.max_colwidth = 100\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Features of the training dataset\n",
    "# data.ix[:,'len_q1':].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data.ix[:,'len_q1':].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Outcome variable of the training dataset\n",
    "# data.ix[:,'is_duplicate'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data.ix[:,'is_duplicate'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preview Prediction\n",
    "# test_prediction[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preview the Prediction Probability [0, 1]\n",
    "# test_prediction_proba[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Displays Results in a Confusion Matrix\n",
    "#Anything on the diagonal was classified correctly and anything off the diagonal was classified incorrectly\n",
    "# pd.crosstab(y_test, test_prediction, rownames=['Actual Similarity'], colnames=['Predicted Similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Displays a list of features that were the most important in affecting the accuracy of the classification\n",
    "# important_features = list(zip(X_train, clf.feature_importances_))\n",
    "# important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Displays the accuracy score of the Random Forest Classifier on the test split\n",
    "# clf_accuracy = accuracy_score(y_test, test_prediction)\n",
    "# clf_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Loads in Quora Test Dataset\n",
    "##########################################\n",
    "#Test Dataset\n",
    "data_test = pd.read_csv('/Users/Priscilla/Desktop/QuoraDataset/test.csv')\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Feature Engineering Method 1: \n",
    "# Creating new input variables to improve ML algorithm performance\n",
    "##########################################\n",
    "#Feature: Length of Question\n",
    "#Apply length function to every data.question1 & data.question2 observation\n",
    "data_test['len_q1'] = data_test.question1.apply(lambda x: len(str(x)))\n",
    "data_test['len_q2'] = data_test.question2.apply(lambda x: len(str(x)))\n",
    "\n",
    "#Feature: Difference in length between the Questions\n",
    "#Substract len_q1 from len_q2\n",
    "data_test['len_diff'] = data_test.len_q1 - data_test.len_q2\n",
    "\n",
    "#Feature: Character count of Question\n",
    "#Strip whitespace in data.question1 & data.question2 and apply the length function\n",
    "data_test['len_char_q1'] = data_test.question1.apply(lambda x: len(str(x).replace(' ', '')))\n",
    "data_test['len_char_q2'] = data_test.question2.apply(lambda x: len(str(x).replace(' ', '')))\n",
    "\n",
    "#Feature: Word count of Question\n",
    "#Call split function on every data.question1 & data.question2 observation and apply the length function\n",
    "data_test['len_word_q1'] = data_test.question1.apply(lambda x: len(str(x).split()))\n",
    "data_test['len_word_q2'] = data_test.question2.apply(lambda x: len(str(x).split()))\n",
    "\n",
    "#Feature: Common words between the Questions\n",
    "#Intersection of data.question1 and data.question2\n",
    "#Set function is applied so repeated words in a question is omitted from the final common word count\n",
    "#Axis=1 to calculate the means column-wise (-->) rather than the default of Axis=0 to calculate the means row-wise(v)\n",
    "data_test['len_common_words'] = data_test.apply(lambda x: len(set(str(x['question1']).lower().split()).intersection(set(str(x['question2']).lower().split()))), axis=1)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Feature Engineering Method 2:\n",
    "# Create Bag Of Words Model with Tfidf Normalization\n",
    "##########################################\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Generate tfidf values for question1 and question2 based on the complete vocabulary of the dataset\n",
    "vectorizer_q1 = TfidfVectorizer(vocabulary = complete_vocab)\n",
    "vectorizer_q2 = TfidfVectorizer(vocabulary = complete_vocab)\n",
    "tfidf_question1 = vectorizer_q1.fit_transform(data_test.question1.values.astype(str))\n",
    "tfidf_question2 = vectorizer_q2.fit_transform(data_test.question2.values.astype(str))\n",
    "\n",
    "#Substract the difference of the tfidf weight matricies for the two questions\n",
    "#Will be 0 if the words are weighted the same in both questions (similar significance contribution)\n",
    "diff_idf = tfidf_question1 - tfidf_question2\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Apply Random Forest Classifer on the Test Dataset\n",
    "##########################################\n",
    "#Features of the test dataset\n",
    "#Method 1 Features\n",
    "#data_test_features = data_test.ix[:,'len_q1':]\n",
    "\n",
    "#Method 2 Features\n",
    "data_test_features = diff_idf\n",
    "\n",
    "#Predicts the outcome variable of the Test Dataset\n",
    "test_prediction = clf.predict(data_test_features)\n",
    "\n",
    "#Prediction probability for the value of the outcome variable (0 or 1)\n",
    "test_prediction_proba = clf.predict_proba(data_test_features)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Create Submission File\n",
    "##########################################\n",
    "submission = pd.DataFrame()\n",
    "submission['test_id'] = data_test.test_id\n",
    "submission['is_duplicate'] = test_prediction\n",
    "\n",
    "submission.to_csv('/Users/Priscilla/Desktop/QuoraDataset/submission.csv', index = False)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2345796"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
