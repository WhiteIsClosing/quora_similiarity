{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier as dt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import naive_bayes\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Loads in Quora Dataset\n",
    "##########################################\n",
    "#Training Dataset\n",
    "data = pd.read_csv('train.csv')\n",
    "data['question1'] = data['question1'].astype(str)\n",
    "data['question2'] = data['question2'].astype(str)\n",
    "\n",
    "test_data = pd.read_csv('test.csv')\n",
    "test_data['question1'] = test_data['question1'].astype(str)\n",
    "test_data['question2'] = test_data['question2'].astype(str)\n",
    "\n",
    "#Drop irrelevant features\n",
    "data = data.drop(['id', 'qid1', 'qid2'], axis=1)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print \"Topic %d:\" % (topic_idx)\n",
    "        print \" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read in the word dictionary\n",
    "complete_word_list = open('word_dictionary_training_set.txt', 'r')\n",
    "word_list = complete_word_list.read().split('\\n')\n",
    "word_list = list(set(word_list))\n",
    "word_list = [x for x in word_list if x != '']\n",
    "total_questions = data['question1'] + data['question2']\n",
    "total_questions = [x for x in total_questions if type(x) != float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Fit a 50 topic LDA model to a vectorized version of the questions\n",
    "vectorizer = CountVectorizer(stop_words='english', vocabulary = word_list)\n",
    "tf = vectorizer.fit_transform(total_questions)\n",
    "lda_fit = LatentDirichletAllocation(n_topics=50).fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Export tf-idf difference, entropy based Random Forest Classifier\n",
    "filename = 'lda_fit.sav'\n",
    "pickle.dump(lda_fit, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#View the top words in the LDA representation\n",
    "no_top_words = 20\n",
    "tf_feature_names = vectorizer.get_feature_names()\n",
    "display_topics(lda_fit, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Train a Random Forest Classifier on the LDA input matrix\n",
    "q1_train = lda_fit.transform(data['question1'])\n",
    "q2_train = lda_fit.transform(data['question2'])\n",
    "training_input = q1_train - q2_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_input, data['is_duplicate'], test_size=0.2)\n",
    "#Create a decision tree classifier object\n",
    "lda_svm_classifier = svm.SVC(kernel='linear')\n",
    "#Train the Decision Forest Classifier\n",
    "lda_svm_classifier.fit(X_train, y_train)\n",
    "#predict on the test set\n",
    "test_prediction = lda_classifier.predict(X_test)\n",
    "print accuracy_score(y_test, test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.473526473526\n",
      "0.444969595819\n",
      "[[ 97   1   0  19   6]\n",
      " [ 53   3   0  39  14]\n",
      " [ 36   1   0  79  19]\n",
      " [ 21   0   0 181  83]\n",
      " [ 20   0   0 136 193]]\n"
     ]
    }
   ],
   "source": [
    "#Print the Accuracy\n",
    "print accuracy_score(y_test, test_prediction)\n",
    "#Print the Precision\n",
    "print precision_score(y_test, test_prediction, average='weighted')\n",
    "#Print the confusion matrix\n",
    "print confusion_matrix(y_test, test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train a linear support vector machine on the tf-idf input matrix using the H&L dictionary\n",
    "tf_vectorizer = TfidfVectorizer(vocabulary = word_list)\n",
    "tf_features = tf_vectorizer.fit_transform(ohio_reviews)\n",
    "X_train, X_test, y_train, y_test = train_test_split(tf_features, ohio_stars, test_size=0.2)\n",
    "#Create a decision tree classifier object\n",
    "tf_classifier = svm.SVC(kernel='linear')\n",
    "#Train the Decision Forest Classifier\n",
    "tf_classifier.fit(X_train, y_train)\n",
    "#Predict on the test set\n",
    "test_prediction = tf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.508491508492\n",
      "0.489525644744\n",
      "[[ 80  20   4  12   5]\n",
      " [ 27  27  17  26   6]\n",
      " [ 19  15  27  61  26]\n",
      " [ 10   2  20 122 128]\n",
      " [  8   2   2  82 253]]\n"
     ]
    }
   ],
   "source": [
    "#Print the Accuracy\n",
    "print accuracy_score(y_test, test_prediction)\n",
    "#Print the Precision\n",
    "print precision_score(y_test, test_prediction, average='weighted')\n",
    "#Print the confusion matrix\n",
    "print confusion_matrix(y_test, test_prediction)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
